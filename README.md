# KAIM-WEEK-6

## Project Overview

This project develops an AI-driven complaint analysis tool for CrediTrust Financial to turn unstructured customer feedback into actionable insights. By leveraging NLP and RAG, the system enables non-technical teams to quickly identify emerging issues across core productsâ€”reducing manual review time and supporting real-time, proactive decision-making.

---

## Project Structure

```
KAIM-WEEK-6/
â”œâ”€â”€ .github/
â”‚ â””â”€â”€ workflows/ # GitHub Actions workflows
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/ # Raw data (should never be modified)
â”‚ â””â”€â”€ processed/ # Processed/cleaned data (gitignored)
â”œâ”€â”€ notebooks/
  â”‚ â””â”€â”€ 1_data_preprocessing_cfpb.ipynb # performs eda and narrative cleaning
â”‚ â””â”€â”€ README.md # Documentation for notebooks
â”œâ”€â”€ scripts/
â”‚ â””â”€â”€ README.md # Documentation for scripts
â”œâ”€â”€ src/
â”‚ â””â”€â”€ utils/ # Utility functions
â”‚  â”‚ â””â”€â”€ data_loader.py # loads csv files
â”‚ â””â”€â”€ vectorize_cimplaints.py # chunking and vectorization
â”‚ â””â”€â”€ inspect_chroma.py # checks if chroma db is created
â”‚ â””â”€â”€ rag_pipeline.py # embedding and llm integration
â”‚ â””â”€â”€ app.py # llm with streamlit
â”‚ â””â”€â”€ README.md # Documentation for src
â”œâ”€â”€ tests/
â”‚ â””â”€â”€ __init__.py # 
â”‚ â””â”€â”€ test_vectorization.py # test compaint vectorization and store creation
â”‚ â””â”€â”€ README.md # Testing documentation
â”œâ”€â”€ vector_store/
â”‚ â””â”€â”€ chroma.sqlite3
â”œâ”€â”€ .gitattributes
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md # Main project documentation
â””â”€â”€ requirements.txt # Python dependencies
```
---
## ğŸ›  Tools & Technologies

- Python  
- Pandas, NumPy  
- Matplotlib, Seaborn (visualization)  
- Jupyter Notebook  
- Git  

---

## Key Task Completed 

### âœ… Task 1: Exploratory Data Analysis and Data Preprocessing 

Loaded the CFPB complaint dataset and conducted initial EDA. Analyzed complaint volume by product and narrative length distribution. Filtered data to include five target products and non-empty narratives. Cleaned text by lowercasing, removing special characters, and stripping boilerplate to prepare for embedding.

### âœ… Task 2: Text Chunking, Embedding, and Vector Store Indexing 

Divided lengthy consumer complaint narratives into manageable text chunks to optimize embedding quality. Generated embeddings for each chunk using a SentenceTransformer model. Created a persistent ChromaDB vector store, ensuring previous collections are deleted to maintain consistency. Verified data integrity by testing chunking output, embedding shapes, and vector store indexing and querying functionality.

### âœ… Task 3: Building the RAG Core Logic and Evaluation 

Loaded the persistent Chroma vector store containing chunked complaint embeddings. Initialized a HuggingFace embedding retriever and integrated it with a high-performance LLM (LLaMA3-70B via Groq). Constructed a Retrieval-Augmented Generation (RAG) chain by combining a context-aware system prompt, the retriever, and the LLM. Enabled the chain to answer domain-specific questions using only the indexed complaint excerpts. Evaluated pipeline quality by running representative queries, inspecting retrieved documents and response accuracy, and measuring retrieval and generation latency.

ğŸ”— Live App: [CrediTrust Complaint Assistant](https://crditrustcomplaintanalysis.streamlit.app/)

---

## âš™ï¸ Setup Instructions

1. **Clone the repository:**

```bash
git clone https://github.com/she-code/KAIM-WEEK-6
cd KAIM-WEEK-6
```

2. **Create and activate a virtual environment:**

```bash
python -m venv venv
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate
```
3. **Install dependencies:**

```bash
pip install -r requirements.txt

```
---
## Contributors
- Frehiwot Abebie
