# KAIM-WEEK-6

## Project Overview

This project develops an AI-driven complaint analysis tool for CrediTrust Financial to turn unstructured customer feedback into actionable insights. By leveraging NLP and RAG, the system enables non-technical teams to quickly identify emerging issues across core productsâ€”reducing manual review time and supporting real-time, proactive decision-making.

---

## Project Structure

```
KAIM-WEEK-6/
â”œâ”€â”€ .github/
â”‚ â””â”€â”€ workflows/ # GitHub Actions workflows
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/ # Raw data (should never be modified)
â”‚ â””â”€â”€ processed/ # Processed/cleaned data (gitignored)
â”œâ”€â”€ notebooks/
  â”‚ â””â”€â”€ 1_data_preprocessing_cfpb.ipynb # performs eda and narrative cleaning
â”‚ â””â”€â”€ README.md # Documentation for notebooks
â”œâ”€â”€ scripts/
â”‚ â””â”€â”€ README.md # Documentation for scripts
â”œâ”€â”€ src/
â”‚ â””â”€â”€ utils/ # Utility functions
â”‚  â”‚ â””â”€â”€ data_loader.py # loads csv files
â”‚ â””â”€â”€ vectorize_cimplaints.py # chunking and vectorization
â”‚ â””â”€â”€ README.md # Documentation for src
â”œâ”€â”€ tests/
â”‚ â””â”€â”€ __init__.py # 
â”‚ â””â”€â”€ test_vectorization.py # test compaint vectorization and store creation
â”‚ â””â”€â”€ README.md # Testing documentation
â”œâ”€â”€ vector_store/
â”‚ â””â”€â”€ chroma.sqlite3
â”œâ”€â”€ .gitattributes
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md # Main project documentation
â””â”€â”€ requirements.txt # Python dependencies
```
---
## ğŸ›  Tools & Technologies

- Python  
- Pandas, NumPy  
- Matplotlib, Seaborn (visualization)  
- Jupyter Notebook  
- Git  

---

## Key Task Completed 

### âœ… Task 1: Exploratory Data Analysis and Data Preprocessing 

Loaded the CFPB complaint dataset and conducted initial EDA. Analyzed complaint volume by product and narrative length distribution. Filtered data to include five target products and non-empty narratives. Cleaned text by lowercasing, removing special characters, and stripping boilerplate to prepare for embedding.

### Task 2: Text Chunking, Embedding, and Vector Store Indexing 

Divided lengthy consumer complaint narratives into manageable text chunks to optimize embedding quality. Generated embeddings for each chunk using a SentenceTransformer model. Created a persistent ChromaDB vector store, ensuring previous collections are deleted to maintain consistency. Verified data integrity by testing chunking output, embedding shapes, and vector store indexing and querying functionality.

---

## âš™ï¸ Setup Instructions

1. **Clone the repository:**

```bash
git clone https://github.com/she-code/KAIM-WEEK-6
cd KAIM-WEEK-6
```

2. **Create and activate a virtual environment:**

```bash
python -m venv venv
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate
```
3. **Install dependencies:**

```bash
pip install -r requirements.txt

```
---
## Contributors
- Frehiwot Abebie
